{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229587cd-b023-4896-8442-6988b35a36ce",
   "metadata": {},
   "source": [
    "Copies [this workflow](https://github.com/jyu-theartofml/kaggle_quora/blob/master/02_LSTM_2Dense_layers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e3ce9-d461-4fc3-a4ae-236979dfa8c4",
   "metadata": {
    "id": "91971b0b-fafa-413a-a0ad-1a573822ace5",
    "tags": []
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc655208-5242-40db-95bd-0b1a93d35906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa5a2f-fb90-4cfe-a337-0f8439675d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create deep copy of data to change\n",
    "data = deepcopy(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487d4ec-e165-4b58-91c0-7bc8dc7cd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['is_duplicate']\n",
    "\n",
    "question1 = list(data['question1'])\n",
    "question2 = list(data['question2'])\n",
    "\n",
    "print(len(question1))\n",
    "print(len(question2))\n",
    "question1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f0132-8406-401a-8cfd-0d859d8e6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit tokenizer\n",
    "tokenizer = Tokenizer(num_words=200000)\n",
    "tokenizer.fit_on_texts(question1+question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39be16-dab6-45c0-831c-e4f5d382d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index #unique words in corpus (training and test sets)\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227ba7a-f722-442c-ac15-83af91dffdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad out sentences\n",
    "q1_data = pad_sequences(question1_word_sequences, maxlen=25)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=25)\n",
    "\n",
    "#ensure target is int\n",
    "labels = np.array(target, dtype=int)\n",
    "#check shapes\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb0d63-3bbb-422c-ba9c-86f89f813842",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85e7b9-3d0f-428c-bd8a-d2351226c30b",
   "metadata": {},
   "source": [
    "[Download glove] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e581a6-ca33-4a00-9dd7-156c19e69c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12f72d-fc2d-447a-8c9c-8ecef443d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6ee41-78c9-4d6d-bc3d-f27e9036981b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454541a7-57ff-415a-9597-0d132b0f6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,GlobalAveragePooling1D,Lambda,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "keras.__version__\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0421bf-6092-45a5-990e-f860584773df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "target = labels\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, test_size=0.25, random_state=126, stratify=target)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_val = X_val[:,0]\n",
    "Q2_val = X_val[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e840bc-d8fe-4add-9c1e-ddeb014fdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "#don't use squar root of the sum, it doens't give a good range to feed to the dense layer.\n",
    "\n",
    "def vec_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eac045-5b98-4dd9-83d8-d09e5be8c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "nb_words=137077+1\n",
    "max_sentence_len=25\n",
    "embedding_layer = Embedding(nb_words,300,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_sentence_len,trainable=False)\n",
    "#dont train this layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0e36f-2df4-46d5-9304-8cc6c5ef58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "lstm_layer =LSTM(128)\n",
    "\n",
    "sequence_1_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "distance=Lambda(vec_distance, output_shape=vec_output_shape)([x1, y1])\n",
    "dense1=Dense(16, activation='sigmoid')(distance)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "\n",
    "bn2 = BatchNormalization()(dense1)\n",
    "prediction=Dense(1, activation='sigmoid')(bn2)\n",
    "\n",
    "model = Model(input=[sequence_1_input, sequence_2_input], output=prediction)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f7ddb-a5fa-47eb-b6af-54f96de4264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['acc'])\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7beaa1-d189-438c-aff2-55e3d1fab4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit([Q1_train, Q2_train], y_train, validation_data=([Q1_val, Q2_val], y_val), verbose=1, \n",
    "          nb_epoch=10, batch_size=256, shuffle=True,class_weight=None, callbacks=[early_stopping])\n",
    "#takes long time to initiate\n",
    "#using dense() layer and sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f6ce7-a4f1-42a0-8237-c9a18c0cdadb",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00335c28-71cb-4a96-9ba2-02fb5a782181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa41d0-a4e6-4f55-a5cf-8b71cb14b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and weights\n",
    "\n",
    "# export model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"brnn_model_distance_128_d16_d05.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"brnn_model_distance_128_d16_d05.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf7f76-b3c8-4f3a-ba2a-7dfc3124f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('lstm_model_distance_128.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"lstm_model_distance_128.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfbf7c-4a84-4b09-b84b-aabb80c354a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict([test1_data, test2_data],verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
