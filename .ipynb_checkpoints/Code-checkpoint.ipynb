{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91971b0b-fafa-413a-a0ad-1a573822ace5",
   "metadata": {
    "id": "91971b0b-fafa-413a-a0ad-1a573822ace5"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb547d5a-3595-44c6-a0b2-445fb0c548ab",
   "metadata": {
    "id": "cb547d5a-3595-44c6-a0b2-445fb0c548ab"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe48c8-1d53-4fe1-a9f1-85a9e3438a04",
   "metadata": {
    "id": "4efe48c8-1d53-4fe1-a9f1-85a9e3438a04"
   },
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4364956-59e8-47c0-8615-da5bacb0c3ef",
   "metadata": {
    "id": "c4364956-59e8-47c0-8615-da5bacb0c3ef"
   },
   "source": [
    "To do:\n",
    "- Follow [this workflow](https://github.com/jyu-theartofml/kaggle_quora/blob/master/02_LSTM_2Dense_layers.ipynb) to try and make an NN\n",
    "- Pickle gridsearch and non gridsearch models on PC\n",
    "- Github together\n",
    "- Presentation outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af44bc-f381-4b24-b814-521a260cda94",
   "metadata": {
    "id": "f2af44bc-f381-4b24-b814-521a260cda94"
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7849e9-0920-4673-959b-7ebb7732baf7",
   "metadata": {
    "id": "6f7849e9-0920-4673-959b-7ebb7732baf7"
   },
   "outputs": [],
   "source": [
    "#trifecta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#gen process\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#NLP process\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Models\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#export model\n",
    "import pickle\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9187deeb-807b-4458-8464-5f1c99893c46",
   "metadata": {
    "id": "9187deeb-807b-4458-8464-5f1c99893c46"
   },
   "outputs": [],
   "source": [
    "#pull custom NLP pre-processing functions\n",
    "%run -i ~/Coding/custom_functions/lighthouse_labs/NLP_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ec19c-2c1f-443f-a0c6-c13a7c20bc56",
   "metadata": {
    "id": "0e5ec19c-2c1f-443f-a0c6-c13a7c20bc56"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753aaf90-feef-4e3b-8ef9-f72c24c472fb",
   "metadata": {
    "id": "753aaf90-feef-4e3b-8ef9-f72c24c472fb",
    "outputId": "6339cae8-863f-4cc3-a502-1f93246341d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download data\n",
    "data_raw = pd.read_csv('train.csv')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0011151c-3d0e-476e-bdf6-5723165ec578",
   "metadata": {
    "id": "0011151c-3d0e-476e-bdf6-5723165ec578"
   },
   "outputs": [],
   "source": [
    "#drop id col (dup of index)\n",
    "data_raw = data_raw.drop(['id', 'qid1', 'qid2'], axis = 1) #[don't think I need qid but I'd like to check that]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aaf9b0-cc51-405f-b95f-e0f423e8882a",
   "metadata": {
    "id": "57aaf9b0-cc51-405f-b95f-e0f423e8882a"
   },
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48419d61-5575-4cdc-88dc-704230cce4b0",
   "metadata": {
    "id": "48419d61-5575-4cdc-88dc-704230cce4b0",
    "outputId": "257d6359-8950-4059-98e9-0406e5199182"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate\n",
       "0    0.630799\n",
       "1    0.369201\n",
       "Name: question1, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get frequency for class (is/isnt duplicate)\n",
    "class_freq = data_raw.groupby('is_duplicate').count().question1\n",
    "\n",
    "class_freq/ data_raw.shape[0] #roughly 60:40 ratio, in interest of time we'll say this is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a982a9c-2d46-4901-a9df-029180b6871e",
   "metadata": {
    "id": "4a982a9c-2d46-4901-a9df-029180b6871e",
    "outputId": "bf45e366-2d27-4f0d-bb0f-d408d2c27878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   question1     404289 non-null  object\n",
      " 1   question2     404288 non-null  object\n",
      " 2   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff6f312-a0af-4ea1-9c3a-34097e5fc3be",
   "metadata": {
    "id": "eff6f312-a0af-4ea1-9c3a-34097e5fc3be",
    "outputId": "308a21d3-5174-4f92-b4f2-5667d94c37ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values\n",
    "data_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272e73ae-37e5-4ec1-8415-94c16873be17",
   "metadata": {
    "id": "272e73ae-37e5-4ec1-8415-94c16873be17",
    "outputId": "083b1a2e-6647-4415-9eca-d70ac173adeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>My Chinese name is Haichao Yu. What English na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question1  \\\n",
       "105780    How can I develop android app?   \n",
       "201841  How can I create an Android app?   \n",
       "363362                               NaN   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "105780                                                NaN             0  \n",
       "201841                                                NaN             0  \n",
       "363362  My Chinese name is Haichao Yu. What English na...             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore the nan\n",
    "data_raw[data_raw.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83df2aa0-258b-4552-be9e-7bcd5d5eccd8",
   "metadata": {
    "id": "83df2aa0-258b-4552-be9e-7bcd5d5eccd8"
   },
   "outputs": [],
   "source": [
    "data_raw = data_raw.drop(data_raw[data_raw.isnull().any(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7453830-cda0-44bd-876e-17812044027f",
   "metadata": {
    "id": "c7453830-cda0-44bd-876e-17812044027f",
    "outputId": "60f9d0ff-a147-4727-8d43-cc846b6f4d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404287 entries, 0 to 404289\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   question1     404287 non-null  object\n",
      " 1   question2     404287 non-null  object\n",
      " 2   is_duplicate  404287 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef4c01-c20b-4774-897b-d22402d6e083",
   "metadata": {
    "id": "adef4c01-c20b-4774-897b-d22402d6e083",
    "tags": []
   },
   "source": [
    "# Cleaning and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b244b6-1918-4fed-9525-57440a10a2c3",
   "metadata": {
    "id": "f7b244b6-1918-4fed-9525-57440a10a2c3"
   },
   "source": [
    "## NLP Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95085e98-b097-4a58-bb49-876083dd0c39",
   "metadata": {
    "id": "95085e98-b097-4a58-bb49-876083dd0c39"
   },
   "outputs": [],
   "source": [
    "#create deep copy of data to change\n",
    "X = deepcopy(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1966dd-860a-4e67-82ee-85b59faade0f",
   "metadata": {
    "id": "3e1966dd-860a-4e67-82ee-85b59faade0f"
   },
   "outputs": [],
   "source": [
    "#clean, stem and tokenize each column of strings\n",
    "X['question1'] = process_features(X['question1']) #with such a big frame this takes a while\n",
    "X['question2'] = process_features(X['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c07d49c-ca92-419e-976c-5a588ec24fbc",
   "metadata": {
    "id": "0c07d49c-ca92-419e-976c-5a588ec24fbc",
    "outputId": "2dab3005-1dec-4328-9d90-6482d9c3ccb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[step, step, guid, invest, share, market, india]</td>\n",
       "      <td>[step, step, guid, invest, share, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[stori, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, govern, stole, kohinoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[increas, speed, internet, connect, use, vpn]</td>\n",
       "      <td>[internet, speed, increas, hack, dn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mental, lone, solv]</td>\n",
       "      <td>[find, remaind, math, math, divid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[one, dissolv, water, quikli, sugar, salt, met...</td>\n",
       "      <td>[fish, would, surviv, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0   [step, step, guid, invest, share, market, india]   \n",
       "1               [stori, kohinoor, kohinoor, diamond]   \n",
       "2      [increas, speed, internet, connect, use, vpn]   \n",
       "3                               [mental, lone, solv]   \n",
       "4  [one, dissolv, water, quikli, sugar, salt, met...   \n",
       "\n",
       "                                           question2  \n",
       "0          [step, step, guid, invest, share, market]  \n",
       "1  [would, happen, indian, govern, stole, kohinoo...  \n",
       "2               [internet, speed, increas, hack, dn]  \n",
       "3                 [find, remaind, math, math, divid]  \n",
       "4                 [fish, would, surviv, salt, water]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperate sentences from target\n",
    "y = X.is_duplicate\n",
    "X = X.drop('is_duplicate', axis=1)\n",
    "\n",
    "X.head() #check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa7bc4-9b23-42b8-bb6d-24b4efadab22",
   "metadata": {
    "id": "e3fa7bc4-9b23-42b8-bb6d-24b4efadab22"
   },
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0abde7-78ee-437a-89e8-66a6af7c3049",
   "metadata": {
    "id": "2a0abde7-78ee-437a-89e8-66a6af7c3049"
   },
   "outputs": [],
   "source": [
    "#use custome function to create similarity score\n",
    "X['similarity'] = similarity_score(X) #apply to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9175653c-1faf-4e9c-b567-197d291ff42a",
   "metadata": {
    "id": "9175653c-1faf-4e9c-b567-197d291ff42a"
   },
   "outputs": [],
   "source": [
    "#split before we are doing fit /transform operation\n",
    "#test train split, also split out labels (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['question1', 'question2', 'similarity']], y, stratify = y, random_state = 42) #default of 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d489e7-5bc9-4a76-b52b-a17f8e32352d",
   "metadata": {
    "id": "57d489e7-5bc9-4a76-b52b-a17f8e32352d"
   },
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f39982b-c4d2-40e4-b8a6-a1a687957f2d",
   "metadata": {
    "id": "4f39982b-c4d2-40e4-b8a6-a1a687957f2d",
    "outputId": "7c7426c0-4843-4a69-852d-fada0e94f6ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, max_features=2500, min_df=7,\n",
       "                preprocessor=<function dummy_fun at 0x14179b3a0>,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function dummy_fun at 0x14179b3a0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorize\n",
    "#so it can handle token data we add this dummy function\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "#instansiate vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 2500, min_df = 7, tokenizer=dummy_fun,\n",
    "                            preprocessor=dummy_fun, max_df = 0.8, stop_words = stopwords.words('english'))\n",
    "    \n",
    "#fit to the entire corpus (question 1 and 2)\n",
    "vectorizer.fit(X_train[['question1', 'question2']].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dabd718a-a95f-4100-a45c-d486fe7bfba3",
   "metadata": {
    "id": "dabd718a-a95f-4100-a45c-d486fe7bfba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303215, 5001)\n",
      "(303215,)\n"
     ]
    }
   ],
   "source": [
    "#use custom functions to get vectors and merge with similarity for single feature input\n",
    "X_train_features = vectors_to_features(X_train)\n",
    "X_test_features = vectors_to_features(X_test)\n",
    "\n",
    "#check the input shape of the data\n",
    "print(X_train_features.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5374bc-fec6-4d00-bac1-8e567de36bef",
   "metadata": {
    "id": "5e5374bc-fec6-4d00-bac1-8e567de36bef"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a19ee-4755-4dcb-b7f8-dafefcc19ab6",
   "metadata": {
    "id": "f85a19ee-4755-4dcb-b7f8-dafefcc19ab6"
   },
   "source": [
    "## Initial Test with RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be70e91-54b9-4fe4-a4c0-f50c45032ffc",
   "metadata": {
    "id": "6be70e91-54b9-4fe4-a4c0-f50c45032ffc"
   },
   "outputs": [],
   "source": [
    "#create dataframe to compare scores\n",
    "comparison_train = pd.DataFrame(index = ['RandomForest', 'LogReg', 'NaiveBayes'], columns = ['recall', 'precision', 'accuracy'])\n",
    "comparison_test = pd.DataFrame(index = ['RandomForest', 'LogReg', 'NaiveBayes'], columns = ['recall', 'precision',  'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a86f3c5-4b6e-451b-9804-655a6b8d7871",
   "metadata": {
    "id": "7a86f3c5-4b6e-451b-9804-655a6b8d7871",
    "outputId": "d2bd8bd3-79da-49f6-cec2-e18f331685d7"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Coding/custom_functions/lighthouse_labs/NLP_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train random forest\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "rfc.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d8313-59b7-4995-9070-26ab2acf1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "#pickle.dump(rfc, open('rfc_default.sav', 'wb'))\n",
    "\n",
    "#load trained model\n",
    "#test it works\n",
    "rfc_default = pickle.load(open('rfc_default.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a61853-e4f0-4da8-aaec-50320cf83794",
   "metadata": {
    "id": "d7a61853-e4f0-4da8-aaec-50320cf83794"
   },
   "outputs": [],
   "source": [
    "y_rfc_train = rfc_default.predict(X_train_features)\n",
    "y_rfc_test = rfc_default.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8dd9f-7935-4a7f-91d6-c5770bac7db2",
   "metadata": {
    "id": "f6a8dd9f-7935-4a7f-91d6-c5770bac7db2",
    "outputId": "1612e49a-ae8e-4e80-dfdb-d20140b90899"
   },
   "outputs": [],
   "source": [
    "comparison_train.loc['RandomForest'] = evaluation(y_rfc_train, y_train)\n",
    "comparison_test.loc['RandomForest'] = evaluation(y_rfc_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f713e7-c809-42c1-baa9-eccda40539a4",
   "metadata": {
    "id": "61f713e7-c809-42c1-baa9-eccda40539a4",
    "outputId": "0403c1a9-9b2d-47af-99cf-723f32c2c003"
   },
   "outputs": [],
   "source": [
    "rfc_default.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf695c-98ff-4a18-8e02-b0f10b1258b0",
   "metadata": {
    "id": "2bcf695c-98ff-4a18-8e02-b0f10b1258b0",
    "tags": []
   },
   "source": [
    "## Other Shallow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62c12d-50d6-4892-90bc-8b32bf7ab34a",
   "metadata": {
    "id": "9f62c12d-50d6-4892-90bc-8b32bf7ab34a"
   },
   "outputs": [],
   "source": [
    "#train naive bayes\n",
    "naive = naive_bayes.MultinomialNB(random_state = 1)\n",
    "naive.fit(X_train_features, y_train)\n",
    "\n",
    "#train logreg\n",
    "lr = LogisticRegression(random_state = 1)\n",
    "lr.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8884789-48b6-4197-86a6-bfeb20e622d5",
   "metadata": {
    "id": "d8884789-48b6-4197-86a6-bfeb20e622d5"
   },
   "outputs": [],
   "source": [
    "y_naive_train = naive.predict(X_train_features)\n",
    "y_lr_train = lr.predict(X_train_features)\n",
    "\n",
    "y_naive = naive.predict(X_test_features)\n",
    "y_lr = lr.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf75ca-7d61-443e-b2b8-6ef56bfdd16c",
   "metadata": {
    "id": "dddf75ca-7d61-443e-b2b8-6ef56bfdd16c"
   },
   "outputs": [],
   "source": [
    "comparison_train.loc['NaiveBayes'] = evaluation(y_naive_train, y_train)\n",
    "comparison_train.loc['LogReg'] = evaluation(y_lr_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc796ff-0c33-45b8-af9b-08bf0e45e764",
   "metadata": {
    "id": "afc796ff-0c33-45b8-af9b-08bf0e45e764"
   },
   "outputs": [],
   "source": [
    "comparison_test.loc['NaiveBayes'] = evaluation(y_naive, y_test)\n",
    "comparison_test.loc['LogReg'] = evaluation(y_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f218b2d-dfa6-476b-91b2-299df69dca43",
   "metadata": {
    "id": "0f218b2d-dfa6-476b-91b2-299df69dca43"
   },
   "outputs": [],
   "source": [
    "comparison_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f2d40-f861-4e93-9698-934aa764d114",
   "metadata": {
    "id": "726f2d40-f861-4e93-9698-934aa764d114"
   },
   "outputs": [],
   "source": [
    "comparison_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab54d1-e41b-476e-b7bd-8b9c70d8ba53",
   "metadata": {
    "id": "e1ab54d1-e41b-476e-b7bd-8b9c70d8ba53",
    "tags": []
   },
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59a6ac-ba49-49a8-8df2-7bebe1c4b857",
   "metadata": {
    "id": "8f59a6ac-ba49-49a8-8df2-7bebe1c4b857"
   },
   "outputs": [],
   "source": [
    "#define hyperparameters to try\n",
    "param_grid = {'max_features': ['auto', 'log2', 'sqrt'],\n",
    "              'min_samples_leaf': [ 5, 10, 20]}\n",
    "\n",
    "#Instantiate random forest with specific parameters\n",
    "rfc_grid = RandomForestClassifier(random_state = 1, n_jobs = -1, n_estimators = 1000, oob_score = True)\n",
    "#instantiant gridsearch with random forest and param grid\n",
    "gridsearch = GridSearchCV(rfc_grid, param_grid, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac63d0-9684-4b53-bc11-06dbf0bb106a",
   "metadata": {
    "id": "91ac63d0-9684-4b53-bc11-06dbf0bb106a",
    "outputId": "493a8924-8cd2-4ba2-fe28-26559de771c3"
   },
   "outputs": [],
   "source": [
    "#gridsearch.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564d278-c99d-45d1-a971-299d60242a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "#pickle.dump(gridsearch, open('rfc_grid.sav', 'wb'))\n",
    "\n",
    "#load trained model\n",
    "pickle.load(open('rfc_grid.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9967b3-e78a-4c1a-99da-9ec0d3dd8ca0",
   "metadata": {
    "id": "ea9967b3-e78a-4c1a-99da-9ec0d3dd8ca0"
   },
   "outputs": [],
   "source": [
    "#gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bd217-2e11-41bb-9fac-a4a4e7ab0c36",
   "metadata": {
    "id": "3d0bd217-2e11-41bb-9fac-a4a4e7ab0c36"
   },
   "outputs": [],
   "source": [
    "#grid_train = gridsearch.predict(X_train_features)\n",
    "#grid_test = gridsearch.predict(X_test_features)\n",
    "\n",
    "#comparison_train.loc['RandomForestGrid'] = evaluation(grid_train, y_train)\n",
    "#comparison_test.loc['RandomForestGrid'] = evaluation(grid_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a267a-7c6e-431a-87b7-d29d08be16b0",
   "metadata": {
    "id": "ba1a267a-7c6e-431a-87b7-d29d08be16b0",
    "tags": []
   },
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a275bf-5776-4f62-8bb3-4df3cdc71a19",
   "metadata": {
    "id": "7b47f0ad-324e-4cd4-ac64-abe2939d24ea"
   },
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfdce65-666d-40b0-92b0-e861de5f2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fb7c355-dc07-4dfd-b0fa-0c3c915e053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create deep copy of data to change\n",
    "data = deepcopy(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb067c23-c57d-4e57-8fec-f5a9af85a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n",
      "404290\n"
     ]
    }
   ],
   "source": [
    "target = data['is_duplicate']\n",
    "\n",
    "question1 = list(data['question1'])\n",
    "question2 = list(data['question2'])\n",
    "\n",
    "print(len(question1))\n",
    "print(len(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7286b7cc-b0c4-41a8-b3c7-5182a20e194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market in india?',\n",
       " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'How can I increase the speed of my internet connection while using a VPN?',\n",
       " 'Why am I mentally very lonely? How can I solve it?',\n",
       " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a52b57-7418-4fa6-8442-fae58592ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit tokenizer\n",
    "tokenizer = Tokenizer(num_words=200000)\n",
    "tokenizer.fit_on_texts(question1+question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809d266-c1f4-4151-96b9-281343977dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index #unique words in corpus (training and test sets)\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f3738-3d4c-480c-b4d5-12806c777905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad out sentences\n",
    "q1_data = pad_sequences(question1_word_sequences, maxlen=25)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=25)\n",
    "\n",
    "#ensure target is int\n",
    "labels = np.array(target, dtype=int)\n",
    "#check shapes\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc0f42-9db1-4e83-a07b-222b1932c311",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f0230-5577-431f-b7c7-602ab6634c6c",
   "metadata": {},
   "source": [
    "[Download glove] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4bed7-de1d-4c3e-bcd4-c1e489725137",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e3076-a0e6-46dd-88e5-726f54fb0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4ccf2-dd5b-4d05-892f-206f306403ab",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dd287-aaf4-4cc1-9829-ddbecb6c39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,GlobalAveragePooling1D,Lambda,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d4347-712d-4830-9490-ec146d479618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "target = labels\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, test_size=0.25, random_state=126, stratify=target)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_val = X_val[:,0]\n",
    "Q2_val = X_val[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c8139-90eb-4575-8e2d-7144360b66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "#don't use squar root of the sum, it doens't give a good range to feed to the dense layer.\n",
    "\n",
    "def vec_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b4ab0-87ae-441f-91a0-2ae9fe6ea031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "nb_words=137077+1\n",
    "max_sentence_len=25\n",
    "embedding_layer = Embedding(nb_words,300,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_sentence_len,trainable=False)\n",
    "#dont train this layer!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
